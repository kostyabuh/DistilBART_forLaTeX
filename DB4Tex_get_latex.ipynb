{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosty\\anaconda3\\envs\\nn_diploma\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#!pip install rapidfuzz -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz.distance import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"kaggle/working/finetuned_model/model_bart\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50264, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latex(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        hypotheses = model.generate(\n",
    "            **inputs, \n",
    "            do_sample=True, \n",
    "            top_p=0.95, \n",
    "            num_return_sequences=1, \n",
    "            repetition_penalty=1.2,\n",
    "            max_length=len(text),\n",
    "            temperature=0.6,\n",
    "            #top_k=50,\n",
    "            min_length=10,\n",
    "            length_penalty=1.0,\n",
    "            #num_beams=5,\n",
    "            no_repeat_ngram_size=2,\n",
    "            #early_stopping=True,\n",
    "        )\n",
    "    for h in hypotheses:\n",
    "        display(Latex(tokenizer.decode(h, skip_special_tokens=True)))\n",
    "        print(tokenizer.decode(h, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305510400"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\sin x+\\cos z^4>  \\varphi \\cdot\\tau'$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\\sin x+\\cos z^4>  \\varphi \\cdot\\tau'$\n"
     ]
    }
   ],
   "source": [
    "#text = 'Число всех возможных чисел не равно 3^6, так как первая цифра должна быть 1 или 2, поэтому количество всех возможных 6 цифр равно 2\\cdot 3\\cdot 3\\cdot 3\\cdot 3\\cdot 3 '\n",
    "#text = 'a * b - c^2 + (x + y) минус десять целых двадцать пять сотых'\n",
    "#text = '1 - синус икс + косинус x больше  -1'\n",
    "#text = \"Скорость космического аппарата зависит от t по формуле v(t) = 10 t**2 - 5\"\n",
    "#text=' \\\\'\n",
    "\n",
    "#text = 'фи умножить на лямбда'\n",
    "\n",
    "#text = 'шинус (икс куб) плюс косинус (зет в четвёртой больше или равны \\phi умножить на тау штрих'\n",
    "\n",
    "#text = '''лямбда прописная квадрат минус три равно десять игрек куб При этом шинус икс равен интеграл от экспоненты до трёх игрек штрих'''\n",
    "\n",
    "#text = 'шинус (икс куб) плюс косинус (зет в четвёртой больше или равны \\phi умножить на тау штрих'\n",
    "\n",
    "#text='\\\\um_{n=1}^\\ifty \\int_0^\\lamba \\\\fac{тангенс 2 \\pi n x)}\\pi n x^{-s-1 dx '\n",
    "\n",
    "#text = 'Предположим, что сигма малая на пять мю плюс икс эквивалентно интегралот 3 до пяти хи строчная квадрат от тау штрих дэ тау штрих '\n",
    "\n",
    "#text = '''У Маши было 1000 рублей пятьдесят семь копеек на карманные расходы каждый день. сто шесть  рублей Маша тратила на яблоки. И тридцать делить на восемь уходило на дорогу.'''\n",
    "\n",
    "\n",
    "\n",
    "#text = 'интеграл от 3 до 5 по икс dx'\n",
    "#text = 'Рассмотрим функцию f(икс) = x в степени 2 + 3x - 2  на интервале от 0 до 5. Найдем значение интеграла от 0 до 5 f (x) dx ).'\n",
    "#text = 'Пусть  g(x) = дробь 1 делить на e в степени x . Найдем значение int{1}{3} g (x) dx.'\n",
    "#text = 'синус икс  плюс 10 равно  косинус ( икс минус 3)'\n",
    "#text = 'икс умножить на игрек - z^2 + (a + b) минус девять целых тридцать четыре сотых'\n",
    "\n",
    "#text = '$ синус икс плюс косинус зет в степени 4 больше   phi умножить на тау штрих'\n",
    "\n",
    "\n",
    "#text = 'интеграл от 3 до 5 по икс dx'\n",
    "\n",
    "#text = 'Пусть  g(x) = дробь 1 делить на e в степени x . Найдем значение int{1}{3} g (x) dx.'\n",
    "text = 'Рассмотрим функциональный ряд  сумма от n=1 до бесконечности у с индексом эн скобка открывается икс скобка закрывается '\n",
    "\n",
    "text = 'sqrt дробь 1 делить на 2 + 10'\n",
    "\n",
    "text = 'икс _2 *10 = 10 + дробь 1 / 3'\n",
    "\n",
    "text = ' \\int_0^\\lamba \\\\fac{2 \\pi f x)}\\pi dx '\\\n",
    "\n",
    "text = 'Рассмотрим функцию f(икс) = x в степени 2 + 3x - 2  на интервале от 0 до 5. Найдем значение интеграла от 0 до 5 f (x) dx ).'\n",
    "\n",
    "text = '$ синус икс плюс косинус зет в степени 4 больше   phi умножить на тау штрих'\n",
    "get_latex(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T00:41:57.625745Z",
     "iopub.status.busy": "2024-05-21T00:41:57.625262Z",
     "iopub.status.idle": "2024-05-21T00:41:57.630807Z",
     "shell.execute_reply": "2024-05-21T00:41:57.629788Z",
     "shell.execute_reply.started": "2024-05-21T00:41:57.625707Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5035322,
     "sourceId": 8451098,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 39971,
     "sourceId": 47737,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 43575,
     "sourceId": 51812,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
